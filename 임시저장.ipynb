{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c7ce7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import MySQLdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e295c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f4330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib 한글화\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "path = 'C:/Windows/Fonts/malgun.ttf'\n",
    "font_name = fm.FontProperties(fname=path, size=50).get_name()\n",
    "plt.rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84b9aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 리스트\n",
    "li_brands = ['CU','롯데슈퍼','이마트','(주)부산경남유통','GS더프래시','세븐일레븐','GS25','GS수퍼마켓','홈플러스',\n",
    "         '롯데마트','신세계백화점','현대백화점','롯데백화점','농협']\n",
    "li_groceries = ['소면','국수','만두','당면','두부','라면','밀가루','부침가루','빵','호떡','만쥬','스프','스페설K','콘푸로스트','콘푸라이트',\n",
    "               '미역국','짜장','카레','오뚜기밥','찰진밥','햇반','우동','야채죽','단팥죽','쇠고기죽','초밥','칩포테이토','포카칩','자일리톨',\n",
    "               '해태아이스쿨','돼지바','메로나','바밤바','새우깡','가나파이','몽쉘크림','초코파이','초콜렛','목캔디','아이비','참크래커',\n",
    "               '마가린','7even','떠먹는불가리스','바이오거트','요플레','이오','불가리스','버터','앱솔루트','분유','프리미엄프레쉬','건강한햄',\n",
    "               '비앤나','롯데햄','소시지','아메리칸후랑크','의성 마늘','우유','드빈치','치즈','슬라이스햄','샌드위치햄','김밥김','맛살',\n",
    "               '꽁치','어묵','참치','고추장','간장','태양초골드','황도','된장','마요네즈','딸기잼','딸기쨈','설탕','벌꿀','꽃소금',\n",
    "               '옥수수유','식용유','콩기름','식초','쌈장','참기름','케찹','해물','델몬트','오렌지','현미녹차','베지밀','두유','생막걸리',\n",
    "               '우국생','HITE','오비골든라거','카스 프레쉬','비타500','비타파워','스프라이트','칠성사이터','삼다수','아이시스','워터라인',\n",
    "               '참이슬','처음처럼','비락식혜','게토레이','파워에이드','포카리스웨트','순보리차','옥수수수염차','레쓰비','맥스웰 하우스',\n",
    "               '맥심 티오피','칸타타','맥심모카골드','테이스터스초이스','프렌치까페','카페라떼','코카콜라','펩시콜라','카페오레','김치',\n",
    "               '콩나물','단무지','월드콘','박카스','배추','부라보콘','구론산','스타벅스','양파','참붕어','몽쉘','칠성사이다','풀무원','스페셜K',\n",
    "               '네스카페','오리온','감자','고구마','버섯','애호박','대파','막걸리','토스트','남양','당근','동서','마늘','시금치','엔젤리너스','오뚜기',\n",
    "               '컨피던스','풋고추','샘표','오이','국내산','고등어','롯데','오징어','백설','삼립','씨그램','레드불','비비고','떡','몬스터','탄산수','청정원',\n",
    "                '오리온','켈로그','팔도','하선정','해태','엔제리너스','스팸','들기름','트레비','굴소스','땅콩','아몬드','적상추','쪽파','생강','양반',\n",
    "                '투게더','줄기 없는 무', '깻잎','가지', '카스','오비라거','자유시간','하이트','핫브레이크']\n",
    "\n",
    "li_meat = ['삼겹살','쇠고기등심','쇠고기불고기','달걀','목초란','토종닭','알짜란','백숙','특란','갈치','삼치','참조기','건강란',\n",
    "          '쇠고기 등심','쇠고기 불고기','돼지고기 목살','부세']\n",
    "\n",
    "li_necessaries = ['페리오','핸드크림','니베아','해피바스','클링스','치약','2080','샴푸','하기스','면도날','3날','린스','컨디셔너',\n",
    "                 '이자녹스 테르비나','iope 슈퍼바이탈','염색','미쟝센','비겐크림폼','선블럭','뉴트로지나','핸드워시','아이!깨끗해',\n",
    "                 '비누','좋은느낌','화이트 New','위스퍼','바디피트','로션','Dr.','바디워시','온더바디','AVEENO','티슈','가그린','리스테린',\n",
    "                 'TRY','BYC','호일','비비안','러닝','비너스','테크','크린','후레시지퍼백','참그린','지퍼락','롯데팩','후레쉬백',\n",
    "                 '키친타올','홈스타','물먹는하마','물먹는 하마','깨끗한나라','항균트리오','페브리즈','비트','무균무때','옥시싹싹',\n",
    "                 '샤프란','락스','피죤','다우니','맥스','가스','크린랩','듀라셀','마미손','위청수','타우스액','까스명수',\n",
    "                 '데톨','후레쉬랩','화이트','향균트리오','데톨','메디안','롯데랩','메디안','벡셀','드봉 스위트로즈','도브','깨끗한 나라','P&G',\n",
    "                  '퍼실','크리넥스','제이디','퍼펙트','에너자이저','닥터','생록천','쉐리','고무장갑','자연퐁','세이프',\n",
    "                 '스파크','어드밴스 캐비티','알프스디','보솜이','표백제','세정제','팬티','컴배트',\n",
    "                 '홈키파','에프킬라','임페리얼','챕스틱','클린앤클리어','오랄비','향균 트리오']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afb16e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def find_brand(x):\n",
    "    global li_brands\n",
    "    for bra in li_brands:\n",
    "        if bra in x:\n",
    "            return bra\n",
    "    return np.nan\n",
    "\n",
    "def categorization(x):\n",
    "    global li_meat\n",
    "    global li_groceries\n",
    "    global li_necessaries\n",
    "    global else_li\n",
    "    if x == '무':\n",
    "        return '식품'\n",
    "    for meat in li_meat:\n",
    "        if meat in x:\n",
    "            return '축산물'\n",
    "    for gro in li_groceries:\n",
    "        if gro in x:\n",
    "            return '식품'\n",
    "    for nec in li_necessaries:\n",
    "        if nec in x:\n",
    "            return '생필품'\n",
    "    return np.nan\n",
    "\n",
    "def find_prod(x):\n",
    "    global all_pro\n",
    "    if x in all_pro:\n",
    "        return x\n",
    "    return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b988e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 \n",
      "2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 \n",
      "2016 2016 2016 2016 2016 2016 2016 2016 2016 2016 2016 2016 \n",
      "2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 \n",
      "2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 \n",
      "2019 2019 2019 2019 2019 2019 2019 2019 2019 2019 2019 2019 \n",
      "2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 \n",
      "2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 \n",
      "end\n"
     ]
    }
   ],
   "source": [
    "# 2014년부터 빠지지 않고 등장하는 상품\n",
    "df_2014_1 = pd.read_csv(r'C:\\Users\\bitcamp\\Desktop\\2022년 1월 가격데이터/2014년 1월 가격데이터.csv', encoding='ansi')\n",
    "all_pro = df_2014_1.상품명.unique()\n",
    "for year in range(2014, 2022):\n",
    "    for month in range(1,13):\n",
    "        df = pd.read_csv(r'C:\\Users\\bitcamp\\Desktop\\2022년 1월 가격데이터/{}년 {}월 가격데이터.csv'.format(year,month), encoding='ansi')\n",
    "        all_pro = np.intersect1d(all_pro, df.상품명.unique())\n",
    "        print(year, end = ' ')\n",
    "    print()\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c103197a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 \n",
      "2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 \n",
      "2016 2016 2016 2016 2016 2016 2016 2016 2016 2016 2016 2016 \n",
      "2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 \n",
      "2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 \n",
      "2019 2019 2019 2019 2019 2019 2019 2019 2019 2019 2019 2019 \n",
      "2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 \n",
      "2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 \n",
      "end\n"
     ]
    }
   ],
   "source": [
    "# # all_pro에 존재하는 품목만 남기고 전처리해서 저장\n",
    "# for year in range(2014, 2022):\n",
    "#     df_year = pd.DataFrame()\n",
    "#     for month in range(1,13):\n",
    "#         df = pd.read_csv(r'C:\\Users\\bitcamp\\Desktop\\2022년 1월 가격데이터/{}년 {}월 가격데이터.csv'.format(year,month), encoding='ansi')\n",
    "#         try:\n",
    "#             df.drop('제조사', axis = 1, inplace=True)\n",
    "#         except:\n",
    "#             pass\n",
    "#         try:\n",
    "#             df.drop('세일여부', axis = 1, inplace=True)\n",
    "#         except:\n",
    "#             pass\n",
    "#         try:\n",
    "#             df.drop('원 플러스 원', axis = 1, inplace=True)\n",
    "#         except:\n",
    "#             pass\n",
    "#         try:\n",
    "#             df.drop('1+1', axis = 1, inplace=True)\n",
    "#         except:\n",
    "#             pass\n",
    "#         df['브랜드'] = df['판매업소'].apply(find_brand)\n",
    "#         df['상품명'] = df['상품명'].apply(find_prod)\n",
    "#         df.dropna(how = 'any', inplace = True)\n",
    "#         df['상품명'] = df.상품명.astype('category')\n",
    "#         df['브랜드'] = df.브랜드.astype('category')\n",
    "#         df['분류'] = df.상품명.apply(categorization)\n",
    "#         df['분류'] = df.분류.astype('category')\n",
    "#         df['조사일'] = '{}-{}'.format(year,month)\n",
    "# # #         df['조사일'] = pd.to_datetime(df.조사일)\n",
    "# # #         df.set_index('브랜드', inplace = True)\n",
    "# #         grouped = df.groupby(['조사일','브랜드','분류']).판매가격.mean()\n",
    "# #         temp = grouped.unstack().reset_index()\n",
    "# #         temp.to_csv(r'C:\\Users\\bitcamp\\Desktop\\2022년 1월 가격데이터\\저장/{}년{}월 평균.csv'.format(year,month), encoding='ansi') \n",
    "#         df.to_csv(r'C:\\Users\\bitcamp\\Desktop\\2022년 1월 가격데이터\\저장/{}년{}월 데이터.csv'.format(year,month), encoding='ansi')\n",
    "#         print(year, end = ' ')\n",
    "#     print()\n",
    "# print('end')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f691005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 \n",
      "2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 \n",
      "2016 2016 2016 2016 2016 2016 2016 2016 2016 2016 2016 2016 \n",
      "2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 \n",
      "2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 \n",
      "2019 2019 2019 2019 2019 2019 2019 2019 2019 2019 2019 2019 \n",
      "2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 \n",
      "2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 \n",
      "end\n"
     ]
    }
   ],
   "source": [
    "# 각 브랜드 별 유지되는 상품 리스트\n",
    "# 각 브랜드 별 상품\n",
    "df_2014_1 = pd.read_csv(r'C:\\Users\\bitcamp\\Desktop\\2022년 1월 가격데이터\\저장/2014년1월 데이터.csv', encoding='ansi')\n",
    "prod_bra = df_2014_1.groupby('브랜드')['상품명'].unique()\n",
    "for year in range(2014, 2022):\n",
    "    for month in range(1,13):\n",
    "        df = pd.read_csv(r'C:\\Users\\bitcamp\\Desktop\\2022년 1월 가격데이터\\저장/{}년{}월 데이터.csv'.format(year,month), encoding='ansi')\n",
    "        for bra in li_brands:\n",
    "            try:\n",
    "                prod_bra[bra] = np.intersect1d(prod_bra[bra], df.groupby('브랜드')['상품명'].unique()[bra])\n",
    "            except:\n",
    "                continue\n",
    "        print(year, end = ' ')\n",
    "    print()\n",
    "print('end')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2ffaf9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 2014 \n",
      "2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 2015 \n",
      "2016 2016 2016 2016 2016 2016 2016 2016 2016 2016 2016 2016 \n",
      "2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 2017 \n",
      "2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 2018 \n",
      "2019 2019 2019 2019 2019 2019 2019 2019 2019 2019 2019 2019 \n",
      "2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 2020 \n",
      "2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 2021 \n",
      "end\n"
     ]
    }
   ],
   "source": [
    "# 각 브랜드 별 유지되는 상품이 아니면 nan값으로\n",
    "df_merge= pd.read_csv(r'C:\\Users\\bitcamp\\Desktop\\2022년 1월 가격데이터\\저장/2014년1월 데이터.csv', encoding='ansi')\n",
    "df_merge.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "df_merge.set_index('브랜드', inplace = True)\n",
    "df_merge = df_merge.sort_values('상품명')\n",
    "\n",
    "for bra in li_brands:\n",
    "    if bra in df.index:\n",
    "        df_merge.loc[bra,'상품명'] = df_merge.loc[bra,'상품명'].apply(lambda x: x if x in prod_bra[bra] else np.nan)\n",
    "\n",
    "for year in range(2014, 2022):\n",
    "    for month in range(1,13):\n",
    "        if year == 2014 and month == 1:\n",
    "            continue\n",
    "        df = pd.read_csv(r'C:\\Users\\bitcamp\\Desktop\\2022년 1월 가격데이터\\저장/{}년{}월 데이터.csv'.format(year,month), encoding='ansi')\n",
    "        df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "        df['조사일'] = pd.to_datetime(df.조사일)\n",
    "#         df = df.sort_values('조사일')\n",
    "#         df = df.fillna(method='ffill')\n",
    "        df.set_index('브랜드', inplace = True)\n",
    "        df = df.sort_values('상품명')\n",
    "        for bra in prod_bra.index:\n",
    "                if bra in df.index:\n",
    "                    df.loc[bra,'상품명'] = df.loc[bra,'상품명'].apply(lambda x: x if x in prod_bra[bra] else np.nan)\n",
    "        df.dropna(inplace = True)\n",
    "        df_merge = df_merge.append(df)\n",
    "#         df.to_csv(r'C:\\Users\\bitcamp\\Desktop\\2022년 1월 가격데이터\\저장/{}년{}월 데이터-1.csv'.format(year,month), encoding='ansi')\n",
    "        print(year, end = ' ')\n",
    "    print()\n",
    "# df_merge.dropna()\n",
    "df_merge.to_csv(r'C:\\Users\\bitcamp\\Desktop\\2022년 1월 가격데이터\\저장/데이터-merge.csv'.format(year,month), encoding='ansi') \n",
    "print('end')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a0ffc39b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1760/4046555158.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\bitcamp\\Desktop\\2022년 1월 가격데이터\\저장/데이터-merge.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ansi'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_dtype_objs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(r'C:\\Users\\bitcamp\\Desktop\\2022년 1월 가격데이터\\저장/데이터-merge.csv', encoding='ansi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "15510792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "# df.set_index('브랜드', inplace = True)\n",
    "# df = df.sort_values('상품명')\n",
    "\n",
    "for bra in li_brands:\n",
    "    if bra in df.index:\n",
    "        df.loc[bra,'상품명'] = df.loc[bra,'상품명'].apply(lambda x: x if x in prod_bra[bra] else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cd296c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>상품명</th>\n",
       "      <th>조사일</th>\n",
       "      <th>판매가격</th>\n",
       "      <th>판매업소</th>\n",
       "      <th>분류</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>브랜드</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>농협</th>\n",
       "      <td>CJ 더 건강한햄 그릴후랑크(350g)</td>\n",
       "      <td>2014-1</td>\n",
       "      <td>5690</td>\n",
       "      <td>농협유통부산점</td>\n",
       "      <td>식품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>농협</th>\n",
       "      <td>CJ 더 건강한햄 그릴후랑크(350g)</td>\n",
       "      <td>2014-1</td>\n",
       "      <td>5580</td>\n",
       "      <td>농협대전유통센터</td>\n",
       "      <td>식품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>농협</th>\n",
       "      <td>CJ 더 건강한햄 그릴후랑크(350g)</td>\n",
       "      <td>2014-1</td>\n",
       "      <td>3980</td>\n",
       "      <td>농협중앙회수원유통센터</td>\n",
       "      <td>식품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>농협</th>\n",
       "      <td>CJ 더 건강한햄 그릴후랑크(350g)</td>\n",
       "      <td>2014-1</td>\n",
       "      <td>5580</td>\n",
       "      <td>농협유통성남점</td>\n",
       "      <td>식품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>농협</th>\n",
       "      <td>CJ 더 건강한햄 그릴후랑크(350g)</td>\n",
       "      <td>2014-1</td>\n",
       "      <td>5580</td>\n",
       "      <td>농협유통성남점</td>\n",
       "      <td>식품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS수퍼마켓</th>\n",
       "      <td>홈스타 곰팡이 싹</td>\n",
       "      <td>2014-1</td>\n",
       "      <td>2980</td>\n",
       "      <td>GS수퍼마켓 대전세이점</td>\n",
       "      <td>생필품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS수퍼마켓</th>\n",
       "      <td>홈스타 곰팡이 싹</td>\n",
       "      <td>2014-1</td>\n",
       "      <td>2980</td>\n",
       "      <td>GS수퍼마켓 울산구영점</td>\n",
       "      <td>생필품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS수퍼마켓</th>\n",
       "      <td>홈스타 제습과 방충을 한번에</td>\n",
       "      <td>2014-1</td>\n",
       "      <td>4650</td>\n",
       "      <td>GS수퍼마켓 종로구기점</td>\n",
       "      <td>생필품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS수퍼마켓</th>\n",
       "      <td>홈스타 제습과 방충을 한번에</td>\n",
       "      <td>2014-1</td>\n",
       "      <td>4650</td>\n",
       "      <td>GS수퍼마켓 종로구기점</td>\n",
       "      <td>생필품</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS수퍼마켓</th>\n",
       "      <td>홈스타 제습과 방충을 한번에</td>\n",
       "      <td>2014-1</td>\n",
       "      <td>4650</td>\n",
       "      <td>GS수퍼마켓 종로구기점</td>\n",
       "      <td>생필품</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9971 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          상품명     조사일  판매가격          판매업소   분류\n",
       "브랜드                                                           \n",
       "농협      CJ 더 건강한햄 그릴후랑크(350g)  2014-1  5690       농협유통부산점   식품\n",
       "농협      CJ 더 건강한햄 그릴후랑크(350g)  2014-1  5580      농협대전유통센터   식품\n",
       "농협      CJ 더 건강한햄 그릴후랑크(350g)  2014-1  3980   농협중앙회수원유통센터   식품\n",
       "농협      CJ 더 건강한햄 그릴후랑크(350g)  2014-1  5580       농협유통성남점   식품\n",
       "농협      CJ 더 건강한햄 그릴후랑크(350g)  2014-1  5580       농협유통성남점   식품\n",
       "...                       ...     ...   ...           ...  ...\n",
       "GS수퍼마켓              홈스타 곰팡이 싹  2014-1  2980  GS수퍼마켓 대전세이점  생필품\n",
       "GS수퍼마켓              홈스타 곰팡이 싹  2014-1  2980  GS수퍼마켓 울산구영점  생필품\n",
       "GS수퍼마켓        홈스타 제습과 방충을 한번에  2014-1  4650  GS수퍼마켓 종로구기점  생필품\n",
       "GS수퍼마켓        홈스타 제습과 방충을 한번에  2014-1  4650  GS수퍼마켓 종로구기점  생필품\n",
       "GS수퍼마켓        홈스타 제습과 방충을 한번에  2014-1  4650  GS수퍼마켓 종로구기점  생필품\n",
       "\n",
       "[9971 rows x 5 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2e97f476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['CU']['상품명'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc14deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
